{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Universo - Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.item import Field\n",
    "from scrapy.item import Item\n",
    "from scrapy.spiders import Spider\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.loader.processors import MapCompose\n",
    "from scrapy.loader import ItemLoader\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Revisar Xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstracción de datos a extraer\n",
    "class Noticia(Item):\n",
    "    id = Field()\n",
    "    titular = Field()\n",
    "    descripcion = Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASE CORE - SPIDER  \n",
    "class ElUniversoSpider(Spider):\n",
    "    name = \"MiSegundoSpider\"\n",
    "    custom_settings = {\n",
    "        'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 Safari/537.36',\n",
    "        # 'FEED_EXPORT_FIELDS': ['id', 'descripcion', 'titular'], # Como ordenar las columnas en el CSV?\n",
    "        # 'CONCURRENT_REQUESTS': 1 # numero de requerimientos concurrentes \n",
    "    }\n",
    "    start_urls = ['https://www.eluniverso.com/deportes']\n",
    "\n",
    "    def parse(self, response):\n",
    "        sel = Selector(response)\n",
    "        noticias = sel.xpath('//div[@class=\"view-content\"]/div[@class=\"posts\"]')\n",
    "        for i, elem in enumerate(noticias): \n",
    "            item = ItemLoader(Noticia(), elem) # Cargo mi item\n",
    "\n",
    "            # Llenando mi item a traves de expresiones XPATH\n",
    "            item.add_xpath('titular', './/h2/a/text()')\n",
    "            item.add_xpath('descripcion', './/p/text()')\n",
    "            item.add_value('id', i)\n",
    "            yield item.load_item() # Retorno mi item lleno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 21:45:05 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: scrapybot)\n",
      "2021-08-23 21:45:05 [scrapy.utils.log] INFO: Versions: lxml 4.6.1.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.19041-SP0\n",
      "2021-08-23 21:45:05 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2021-08-23 21:45:05 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '\n",
      "               'like Gecko) Ubuntu Chromium/71.0.3578.80 Chrome/71.0.3578.80 '\n",
      "               'Safari/537.36'}\n",
      "2021-08-23 21:45:05 [scrapy.extensions.telnet] INFO: Telnet Password: 65076a5ff5f1e7f2\n",
      "2021-08-23 21:45:05 [py.warnings] WARNING: C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\scrapy\\extensions\\feedexport.py:247: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n",
      "2021-08-23 21:45:05 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-08-23 21:45:06 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-08-23 21:45:06 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-08-23 21:45:06 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-08-23 21:45:06 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-08-23 21:45:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-08-23 21:45:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-08-23 21:45:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.eluniverso.com/deportes/> from <GET https://www.eluniverso.com/deportes>\n",
      "2021-08-23 21:45:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.eluniverso.com/deportes/> (referer: None)\n",
      "2021-08-23 21:45:06 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-08-23 21:45:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 768,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 71099,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'downloader/response_status_count/301': 1,\n",
      " 'elapsed_time_seconds': 0.576898,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 8, 23, 19, 45, 6, 830049),\n",
      " 'httpcompression/response_bytes': 429678,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'log_count/WARNING': 1,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2021, 8, 23, 19, 45, 6, 253151)}\n",
      "2021-08-23 21:45:06 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "# Corremos el código\n",
    "process = CrawlerProcess({\n",
    "     'FEED_FORMAT': 'json',\n",
    "     'FEED_URI': 'datos_de_salida.json'\n",
    "})\n",
    "process.crawl(ElUniversoSpider)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
